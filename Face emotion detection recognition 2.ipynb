{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54753d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b33dc4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_csv('fer2013.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1b350b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 3\n",
      "Number of rows: 35887\n"
     ]
    }
   ],
   "source": [
    "# Print the number of columns in the DataFrame\n",
    "print(\"Number of columns:\", len(df.columns))\n",
    "\n",
    "# Print the number of rows in the DataFrame\n",
    "print(\"Number of rows:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90e4e475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: ['emotion', 'pixels', 'Usage']\n"
     ]
    }
   ],
   "source": [
    "# Print the column names\n",
    "print(\"Column names:\", list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "713d474e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion    False\n",
      "pixels     False\n",
      "Usage      False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Check for any NaN values\n",
    "print(df.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89d0d607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion    0\n",
      "pixels     0\n",
      "Usage      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of NaN values in each column\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17cb0f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "for index, row in df.iterrows():\n",
    "    k = row['pixels'].split(\" \")\n",
    "    if row['Usage'] == 'Training':\n",
    "        X_train.append(np.array(k))\n",
    "        y_train.append(row['emotion'])\n",
    "    elif row['Usage'] == 'PublicTest':\n",
    "        X_test.append(np.array(k))\n",
    "        y_test.append(row['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07761725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['70', '80', '82', ..., '106', '109', '82'], dtype='<U3')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4808533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train, dtype = 'uint8')\n",
    "y_train = np.array(y_train, dtype = 'uint8')\n",
    "X_test = np.array(X_test, dtype = 'uint8')\n",
    "y_test = np.array(y_test, dtype = 'uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17ddbb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "y_train= to_categorical(y_train, num_classes=7)\n",
    "y_test = to_categorical(y_test, num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed658ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "109a2d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "datagen = ImageDataGenerator( \n",
    "    rescale=1./255,\n",
    "    rotation_range = 10,\n",
    "    horizontal_flip = True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    fill_mode = 'nearest')\n",
    "testgen = ImageDataGenerator(rescale=1./255)\n",
    "datagen.fit(X_train)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b8758d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_flow = datagen.flow(X_train, y_train, batch_size=batch_size) \n",
    "test_flow = testgen.flow(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c3131b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "#from keras.layers.merge import concatenate\n",
    "from keras.layers import concatenate\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.regularizers import l1, l2\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "850a16a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FER_Model(input_shape=(48,48,1)):\n",
    "    # first input model\n",
    "    visible = Input(shape=input_shape, name='input')\n",
    "    num_classes = 7\n",
    "    #the 1-st block\n",
    "    conv1_1 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_1')(visible)\n",
    "    conv1_1 = BatchNormalization()(conv1_1)\n",
    "    conv1_2 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_2')(conv1_1)\n",
    "    conv1_2 = BatchNormalization()(conv1_2)\n",
    "    pool1_1 = MaxPooling2D(pool_size=(2,2), name = 'pool1_1')(conv1_2)\n",
    "    drop1_1 = Dropout(0.3, name = 'drop1_1')(pool1_1)#the 2-nd block\n",
    "    conv2_1 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_1')(drop1_1)\n",
    "    conv2_1 = BatchNormalization()(conv2_1)\n",
    "    conv2_2 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_2')(conv2_1)\n",
    "    conv2_2 = BatchNormalization()(conv2_2)\n",
    "    conv2_3 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_3')(conv2_2)\n",
    "    conv2_2 = BatchNormalization()(conv2_3)\n",
    "    pool2_1 = MaxPooling2D(pool_size=(2,2), name = 'pool2_1')(conv2_3)\n",
    "    drop2_1 = Dropout(0.3, name = 'drop2_1')(pool2_1)#the 3-rd block\n",
    "    conv3_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_1')(drop2_1)\n",
    "    conv3_1 = BatchNormalization()(conv3_1)\n",
    "    conv3_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_2')(conv3_1)\n",
    "    conv3_2 = BatchNormalization()(conv3_2)\n",
    "    conv3_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_3')(conv3_2)\n",
    "    conv3_3 = BatchNormalization()(conv3_3)\n",
    "    conv3_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_4')(conv3_3)\n",
    "    conv3_4 = BatchNormalization()(conv3_4)\n",
    "    pool3_1 = MaxPooling2D(pool_size=(2,2), name = 'pool3_1')(conv3_4)\n",
    "    drop3_1 = Dropout(0.3, name = 'drop3_1')(pool3_1)#the 4-th block\n",
    "    conv4_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_1')(drop3_1)\n",
    "    conv4_1 = BatchNormalization()(conv4_1)\n",
    "    conv4_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_2')(conv4_1)\n",
    "    conv4_2 = BatchNormalization()(conv4_2)\n",
    "    conv4_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_3')(conv4_2)\n",
    "    conv4_3 = BatchNormalization()(conv4_3)\n",
    "    conv4_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_4')(conv4_3)\n",
    "    conv4_4 = BatchNormalization()(conv4_4)\n",
    "    pool4_1 = MaxPooling2D(pool_size=(2,2), name = 'pool4_1')(conv4_4)\n",
    "    drop4_1 = Dropout(0.3, name = 'drop4_1')(pool4_1)\n",
    "    #the 5-th block\n",
    "    conv5_1 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_1')(drop4_1)\n",
    "    conv5_1 = BatchNormalization()(conv5_1)\n",
    "    conv5_2 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_2')(conv5_1)\n",
    "    conv5_2 = BatchNormalization()(conv5_2)\n",
    "    conv5_3 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_3')(conv5_2)\n",
    "    conv5_3 = BatchNormalization()(conv5_3)\n",
    "    conv5_4 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_4')(conv5_3)\n",
    "    conv5_3 = BatchNormalization()(conv5_3)\n",
    "    pool5_1 = MaxPooling2D(pool_size=(2,2), name = 'pool5_1')(conv5_4)\n",
    "    drop5_1 = Dropout(0.3, name = 'drop5_1')(pool5_1)#Flatten and output\n",
    "    flatten = Flatten(name = 'flatten')(drop5_1)\n",
    "    ouput = Dense(num_classes, activation='softmax', name = 'output')(flatten)# create model \n",
    "    model = Model(inputs =visible, outputs = ouput)\n",
    "    # summary layers\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df92f6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 48, 48, 1)]       0         \n",
      "                                                                 \n",
      " conv1_1 (Conv2D)            (None, 48, 48, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 48, 48, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1_2 (Conv2D)            (None, 48, 48, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 48, 48, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " pool1_1 (MaxPooling2D)      (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " drop1_1 (Dropout)           (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv2_1 (Conv2D)            (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2_2 (Conv2D)            (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2_3 (Conv2D)            (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " pool2_1 (MaxPooling2D)      (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " drop2_1 (Dropout)           (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " conv3_1 (Conv2D)            (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 12, 12, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv3_2 (Conv2D)            (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 12, 12, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv3_3 (Conv2D)            (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 12, 12, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv3_4 (Conv2D)            (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 12, 12, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " pool3_1 (MaxPooling2D)      (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " drop3_1 (Dropout)           (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " conv4_1 (Conv2D)            (None, 6, 6, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 6, 6, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv4_2 (Conv2D)            (None, 6, 6, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 6, 6, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv4_3 (Conv2D)            (None, 6, 6, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 6, 6, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv4_4 (Conv2D)            (None, 6, 6, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 6, 6, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " pool4_1 (MaxPooling2D)      (None, 3, 3, 256)         0         \n",
      "                                                                 \n",
      " drop4_1 (Dropout)           (None, 3, 3, 256)         0         \n",
      "                                                                 \n",
      " conv5_1 (Conv2D)            (None, 3, 3, 512)         1180160   \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 3, 3, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv5_2 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 3, 3, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv5_3 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 3, 3, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv5_4 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " pool5_1 (MaxPooling2D)      (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " drop5_1 (Dropout)           (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 7)                 3591      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,111,367\n",
      "Trainable params: 13,103,431\n",
      "Non-trainable params: 7,936\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = FER_Model()\n",
    "opt = Adam(learning_rate=0.0001, decay=1e-6)\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "116afd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "filepath = './model_checkpoint.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                          min_delta=0,\n",
    "                          patience=3,\n",
    "                          verbose=1,\n",
    "                          restore_best_weights=True\n",
    "                          )\n",
    "\n",
    "reduce_learningrate = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.2,\n",
    "                              patience=3,\n",
    "                              verbose=1,\n",
    "                              min_delta=0.0001)\n",
    "callbacks_list = [early_stopping,checkpoint,reduce_learningrate]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "edbb9f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59a4e18c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "449/448 [==============================] - ETA: -3s - loss: 1.1884 - accuracy: 0.5657\n",
      "Epoch 1: val_accuracy improved from -inf to 0.52577, saving model to .\\model_checkpoint.h5\n",
      "448/448 [==============================] - 3381s 8s/step - loss: 1.1884 - accuracy: 0.5657 - val_loss: 1.3120 - val_accuracy: 0.5258 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "449/448 [==============================] - ETA: -3s - loss: 1.1244 - accuracy: 0.5871\n",
      "Epoch 2: val_accuracy improved from 0.52577 to 0.53720, saving model to .\\model_checkpoint.h5\n",
      "448/448 [==============================] - 3452s 8s/step - loss: 1.1244 - accuracy: 0.5871 - val_loss: 1.3532 - val_accuracy: 0.5372 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "449/448 [==============================] - ETA: -3s - loss: 1.1019 - accuracy: 0.5951\n",
      "Epoch 3: val_accuracy improved from 0.53720 to 0.55977, saving model to .\\model_checkpoint.h5\n",
      "448/448 [==============================] - 3379s 8s/step - loss: 1.1019 - accuracy: 0.5951 - val_loss: 1.1914 - val_accuracy: 0.5598 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "449/448 [==============================] - ETA: -3s - loss: 1.0451 - accuracy: 0.6128\n",
      "Epoch 4: val_accuracy improved from 0.55977 to 0.56088, saving model to .\\model_checkpoint.h5\n",
      "448/448 [==============================] - 3473s 8s/step - loss: 1.0451 - accuracy: 0.6128 - val_loss: 1.2037 - val_accuracy: 0.5609 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "449/448 [==============================] - ETA: -3s - loss: 1.0298 - accuracy: 0.6215\n",
      "Epoch 5: val_accuracy improved from 0.56088 to 0.58735, saving model to .\\model_checkpoint.h5\n",
      "448/448 [==============================] - 3415s 8s/step - loss: 1.0298 - accuracy: 0.6215 - val_loss: 1.1376 - val_accuracy: 0.5874 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "449/448 [==============================] - ETA: -3s - loss: 0.9995 - accuracy: 0.6321\n",
      "Epoch 6: val_accuracy did not improve from 0.58735\n",
      "448/448 [==============================] - 3510s 8s/step - loss: 0.9995 - accuracy: 0.6321 - val_loss: 1.2066 - val_accuracy: 0.5651 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "449/448 [==============================] - ETA: -3s - loss: 0.9832 - accuracy: 0.6405\n",
      "Epoch 7: val_accuracy improved from 0.58735 to 0.61688, saving model to .\\model_checkpoint.h5\n",
      "448/448 [==============================] - 3340s 7s/step - loss: 0.9832 - accuracy: 0.6405 - val_loss: 1.0523 - val_accuracy: 0.6169 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "449/448 [==============================] - ETA: -10s - loss: 0.9650 - accuracy: 0.6487\n",
      "Epoch 8: val_accuracy improved from 0.61688 to 0.64948, saving model to .\\model_checkpoint.h5\n",
      "448/448 [==============================] - 11647s 26s/step - loss: 0.9650 - accuracy: 0.6487 - val_loss: 0.9949 - val_accuracy: 0.6495 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "449/448 [==============================] - ETA: -3s - loss: 0.9447 - accuracy: 0.6554\n",
      "Epoch 9: val_accuracy did not improve from 0.64948\n",
      "448/448 [==============================] - 3302s 7s/step - loss: 0.9447 - accuracy: 0.6554 - val_loss: 1.0209 - val_accuracy: 0.6375 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "449/448 [==============================] - ETA: -3s - loss: 0.9208 - accuracy: 0.6624\n",
      "Epoch 10: val_accuracy did not improve from 0.64948\n",
      "448/448 [==============================] - 3548s 8s/step - loss: 0.9208 - accuracy: 0.6624 - val_loss: 1.0826 - val_accuracy: 0.6194 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "449/448 [==============================] - ETA: -3s - loss: 0.9059 - accuracy: 0.6715Restoring model weights from the end of the best epoch: 8.\n",
      "\n",
      "Epoch 11: val_accuracy did not improve from 0.64948\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "448/448 [==============================] - 3399s 8s/step - loss: 0.9059 - accuracy: 0.6715 - val_loss: 1.1078 - val_accuracy: 0.6038 - lr: 0.0010\n",
      "Epoch 11: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(filepath)\n",
    "history = model.fit(train_flow, \n",
    "                              steps_per_epoch=len(X_train) / batch_size, \n",
    "                             epochs=60, \n",
    "                              verbose=1, \n",
    "                              validation_data=test_flow,\n",
    "                              validation_steps=len(X_test) / batch_size, \n",
    "                                callbacks=callbacks_list\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c801307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"detection_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"detection_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0f0541",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
